{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Project Proposal"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Bram Simonnet\n",
    "- Elan Hashem \n",
    "- Brooks Ephraim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our project focuses on optimizing algorithmic trading strategies using different AI algorithms to maximize trading performance. The goal is to develop a model that can generate effective buy/sell decisions based on historical market data. We will utilize a dataset containing stock price movements, trading volume, and technical indicators, measured at regular intervals to capture market trends. Our approach will involve training and evaluating different AI models, including reinforcement learning techniques, incorporating dynamic programming and evaluating the value differences in state-action pairs, to predict profitable trading actions. Additionally, we will explore feature engineering to enhance model inputs and improve predictive accuracy. Performance will be measured using key financial metrics such as the Sharpe ratio, total return, and maximum drawdown, ensuring that the strategy balances profitability and risk. To ensure robustness, we will test our model across different market conditions and asset classes. By backtesting our model on historical data, we aim to determine its effectiveness in real-world trading scenarios.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "Algorithmic trading has revolutionized financial markets by enabling high-speed, data-driven decision-making that surpasses human capabilities[1][2]. The integration of machine learning (ML) and reinforcement learning (RL) has further enhanced these systems, allowing for adaptive strategies that respond to dynamic market conditions[3][4]. This project builds on foundational work in quantitative finance, where ML models such as neural networks and ensemble methods have demonstrated empirical success in predicting price movements and optimizing trade execution[3][5]. For instance, neural networks have been shown to identify non-linear patterns in historical data that traditional statistical methods often miss[3][6], while ensemble techniques like gradient-boosted decision trees improve robustness against market noise[5][6].\n",
    "Reinforcement learning has emerged as a particularly promising paradigm for algorithmic trading due to its ability to optimize decision-making processes through trial-and-error interactions with market environments[4][7]. Unlike supervised learning, which relies on static datasets, RL agents learn policies that maximize cumulative rewards—a framework naturally aligned with trading’s sequential decision-making requirements[4]. Recent studies, such as those by Pricope (2021), highlight DRL’s capacity to handle high-dimensional state spaces, including order book dynamics and macroeconomic indicators[4]. Empirical results from cryptocurrency markets demonstrate that RL-based strategies can achieve 31.53% returns under volatile conditions, outperforming traditional rule-based systems by 22 percentage points[7]. These advancements underscore RL’s potential to adapt strategies in real time while managing transaction costs and market impact[7][8].\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This project advances prior work by rigorously evaluating model performance across varying market conditions—a gap identified in recent literature reviews[1]. By testing strategies on equities, cryptocurrencies, and commodities, the analysis addresses concerns about strategy robustness raised by Gerner-Beuerle (2021), who documented algorithmic trading’s role in amplifying volatility during the 2010 Flash Crash[1]. Furthermore, the incorporation of dynamic programming principles enables real-time portfolio rebalancing, optimizing position sizing while adhering to risk constraints[9]. Through comprehensive backtesting against metrics like the Sharpe ratio and maximum drawdown[7][5], the project provides a framework for developing AI-driven trading systems that balance profitability with stability in evolving financial ecosystems.\n",
    "\n",
    "\n",
    "This synthesis of RL adaptability, feature engineering, and cross-market validation positions the project to contribute meaningfully to the $1.5 trillion algorithmic trading industry, where even marginal improvements in strategy efficiency yield substantial economic impacts[1][2].\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Financial markets are highly volatile, making it difficult to develop trading strategies that consistently generate high returns while controlling risk. Traditional rule-based approaches lack adaptability, often resulting in suboptimal performance. This project aims to enhance algorithmic trading strategies using machine learning, particularly reinforcement learning for sequential decision-making and supervised learning for pattern recognition. Trading decisions will be optimized through policy evaluation and dynamic programming techniques to improve long-term profitability. Strategy effectiveness will be assessed using financial metrics such as the Sharpe ratio, total return, and maximum drawdown, ensuring a balance between reward and risk. By backtesting on historical market data, the model’s adaptability and robustness across varying market conditions will be validated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "## Data set 1: Yahoo Finance \n",
    "Link: Use the Yahoo Finance API or Python’s yfinance package.\n",
    "Size:\n",
    "Stock data for hundreds of companies, spanning decades.\n",
    "Each company has millions of observations depending on historical depth (e.g., daily, minute data).\n",
    "Observation Format:\n",
    "Each row is a timestamped stock price (e.g., daily or minute-based).\n",
    "Critical Variables:\n",
    "Open, High, Low, Close (OHLC) prices.\n",
    "Volume (trading activity).\n",
    "Adjusted Close (price adjusted for stock splits/dividends).\n",
    "Data Cleaning/Handling:\n",
    "Handle missing values (e.g., market closures).\n",
    "Normalize price data for better RL training.\n",
    "Convert timestamps to Unix format for easier time-series processing.\n",
    "Add technical indicators (e.g., moving averages, RSI, MACD) for better state representation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "The proposed solution is to train a Reinforcement Learning (RL) agent to optimize an algorithmic trading strategy using stock market data. The RL agent will interact with a simulated trading environment where it learns to maximize long-term returns by making sequential decisions (buy, sell, or hold). The agent will be trained using historical stock market data and then tested on unseen data to evaluate its performance and generalizability.\n",
    "The RL problem will be formulated as a Markov Decision Process (MDP):\n",
    "- State (S): A feature vector representing the market at time ttt, including:\n",
    "  OHLCV (Open, High, Low, Close, Volume) data.\n",
    "Technical indicators (SMA, RSI, MACD, Bollinger Bands).\n",
    "Position status (current holdings, cash balance).\n",
    "Market trends (moving averages, volatility).\n",
    "- Action (A): The agent chooses from:\n",
    "Buy: Purchase stock at the current price.\n",
    "Sell: Sell stock at the current price.\n",
    "Hold: Maintain current position.\n",
    "- Reward (R): The reward function incentivizes profitable trades:\n",
    "Rt=Pt+1−PtR_t = P_{t+1} - P_tRt​=Pt+1​−Pt​ (profit/loss per trade)\n",
    "Penalize holding losing positions too long.\n",
    "Introduce transaction cost penalties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "## 1. Profitability & Returns\n",
    "Sharpe Ratio: \n",
    "Measures risk-adjusted return. A higher ratio indicates better risk-reward tradeoff.  \n",
    "Sharpe Ratio = (Rx – Rf) / StdDev Rx\n",
    "Rx = Expected portfolio return \n",
    "Rf = Risk-free rate of return. \n",
    "StdDev Rx = Standard deviation of portfolio return (or, volatility)\n",
    "\n",
    "\n",
    "Total Return (%): The cumulative profit or loss over a backtesting period.  \n",
    "\n",
    "\n",
    "Maximum Drawdown (MDD): Measures the worst peak-to-trough decline, important for risk assessment.  \n",
    "\n",
    "\n",
    "MDD = (Trough Value – Peak Value) / Peak Value\n",
    "\n",
    "## 2. Model Performance & Trading Execution\n",
    "Win/Loss Ratio: The number of profitable trades vs. losing trades.  \n",
    "Precision & Recall in Trade Execution: Measures how well the AI identifies high-probability trading opportunities.  \n",
    "Execution Latency: Measures how quickly the AI executes trades in simulated environments.  \n",
    "## 3. Stability & Generalization\n",
    "Out-of-Sample Performance: We can train on historical data (like 2010-2020) and test on newer unseen data (like 2021-2024).  \n",
    "Robustness Across Asset Classes: Testing performance on stocks, cryptocurrencies, and commodities to evaluate model generalization.  \n",
    "Comparative Analysis Against Benchmarks**:  \n",
    "Compare AI model to a random trading strategy (baseline).  \n",
    "Compare AI model to traditional rule-based technical analysis strategies (like moving averages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of an RL-based algorithmic trading system raises ethical concerns, including market manipulation risks (e.g., spoofing, front-running), data privacy issues, biases, wealth inequality, and black-box decision-making. To mitigate these, our approach ensures compliance with financial regulations, integrates ethical constraints into the reward function, and prevents overfitting by training on diverse market conditions. Security measures include encrypted API authentication and restricted data access to protect sensitive information. Additionally, we incorporate explainability techniques (e.g., SHAP, LIME) to provide transparency, enforce circuit breakers to prevent extreme trades, and advocate for a hybrid human-in-the-loop system to balance automation with oversight. Our commitment to responsible AI ensures fairness, security, and accountability while optimizing trading strategies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put things here that cement how you will interact/communicate as a team, how you will handle conflict and difficulty, how you will handle making decisions and setting goals/schedule, how much work you expect from each other, how you will handle deadlines, etc...\n",
    "### Logistics\n",
    " - Out-of-Sample Performance\n",
    "    We can train on historical data (like 2010-2020) and test on newer unseen data (like 2021-2024).\n",
    "\n",
    "- Robustness Across Asset Classes\n",
    "    Testing performance on stocks, cryptocurrencies, and commodities to evaluate model  generalization.\n",
    "\n",
    "- Comparative Analysis Against Benchmarks\n",
    "- Compare AI model to a random trading strategy (baseline).\n",
    "- Compare AI model to traditional rule-based technical analysis strategies (like moving averages).\n",
    "### Workload Distribution / Accountability\n",
    "- Each team member will be responsible for specific tasks and expected to complete them before the agreed deadlines.\n",
    "- All major decisions (like model selection, dataset changes) will be discussed as a team before implementation.\n",
    "- Members will check in regularly to ensure alignment and address any roadblocks.\n",
    "### Conflict Resolution\n",
    "- If disagreements arise, we will resolve them through open discussion.\n",
    "- All members are able to voice their opinions/concerns, and all members must listen and respect these.\n",
    "- If a member consistently fails to meet deadlines or contribute, the issue will be addressed as a group before escalating to the instructor if necessary.\n",
    "### Deadlines & Final Deliverables\n",
    "- Each phase of the project will have clear deadlines on the Google Doc to ensure that these are all met.\n",
    "- The final report and codebase will be reviewed by all team members before submission to ensure quality and completeness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time | Completed Before Meeting  | Discuss at Meeting |\n",
    "|--------------|-------------|---------------------------|---------------------|\n",
    "| 10/02       | 5 PM        | Brainstorm project ideas (all); Finalize project topic, research datasets, outline proposal | Decide on final project topic and dataset; Outline proposal |\n",
    "| 13/02       | 5 PM        | Conduct background research, read financial AI papers (all); Evaluate dataset quality (Elan); Explore existing AI trading strategies (Bram) | Discuss dataset choices; Finalize proposal draft |\n",
    "| 14/02       | 1 PM        | Clean up proposal draft (Bram, Elan); Prepare citations (Brooks); Draft feature engineering ideas (all) | Submit proposal; Assign coding roles; Finalize GitHub repo setup |\n",
    "| 18/02       | 6 PM        | Download & preprocess dataset (Bram); Conduct exploratory data analysis (Brooks, Elan) | Review data wrangling; Discuss RL environment setup |\n",
    "| 21/02       | 1 PM        | Begin reinforcement learning model training (all); Implement baseline model (simple moving average strategy) (Bram); Test initial RL agent in simulation environment (Elan, Brooks) | Debug training issues; Tune hyperparameters |\n",
    "| 27/02       | 4 PM        | Conduct initial backtesting and performance evaluation (all); Evaluate benchmark model vs. RL performance (Brooks, Elan); Refine hyperparameter tuning (Bram) | Analyze trading results; Compare to benchmark strategies |\n",
    "| 01/03       | 12 PM       | Run final model tests on out-of-sample data (all); Generate visualizations (Bram, Brooks) | Finalize results; Begin writing report |\n",
    "| 11/03       | 4 PM        | Complete project analysis; Format final report; Finalize code documentation (all) | Submit final report and code on GitHub |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "1. **Oyeniyi, L.D.** (13 April 2024) *Analyzing the impact of algorithmic trading on stock market behavior: A comprehensive review.*  \n",
    "   *Word Journal of Advanced Engineering Technology and Sciences.*  \n",
    "   [Link](https://wjaets.com/sites/default/files/WJAETS-2024-0136.pdf)\n",
    "\n",
    "2. **Seth, S.** (14 Dec 2023) *Basics of Algorithmic Trading: Concepts and Examples.*  \n",
    "   *Investopedia.*  \n",
    "   [Link](https://www.investopedia.com/articles/active-trading/101014/basics-algorithmic-trading-concepts-and-examples.asp)\n",
    "\n",
    "3. **Kumar, R.** (30 June 2024) *Machine Learning Algorithms for Algorithmic Trading: An Empirical Study.*  \n",
    "   *International Journal of Interdisciplinary Finance Insights.*  \n",
    "   [Link](https://injmr.com/index.php/ijifi/article/view/114)\n",
    "\n",
    "4. **Pricope, T.** (31 May 2021) *Deep Reinforcement Learning in Quantitative Algorithmic Trading: A Review.*  \n",
    "   *Semantic Scholar.*  \n",
    "   [Link](https://injmr.com/index.php/ijifi/article/view/114)\n",
    "\n",
    "5. **Salehpour, A.** (8 Dec 2023) *Machine Learning Applications in Algorithmic Trading: A Comprehensive Systematic Review.*  \n",
    "   *International Journal of Education and Management Engineering.*  \n",
    "   [Link](https://www.mecs-press.org/ijeme/ijeme-v13-n6/v13n6-5.html)\n",
    "\n",
    "6. **Grudniewicz, J.** (Oct 2023) *Application of Machine Learning in Algorithmic Investment Strategies on Global Stock Markets.*  \n",
    "   *Research in International Business and Finance.*  \n",
    "   [Link](https://www.sciencedirect.com/science/article/pii/S0275531923001782)\n",
    "\n",
    "7. **Yang, H.** (11 Dec 2024) *Reinforcement Learning Pair Trading: A Dynamic Scaling Approach.*  \n",
    "   *Journal of Risk and Financial Management.*  \n",
    "   [Link](https://www.mdpi.com/1911-8074/17/12/555)\n",
    "\n",
    "8. **Felizardo, L.K.** (15 Sept. 2022) *Outperforming Algorithmic Trading Reinforcement Learning Systems: A Supervised Approach to the Cryptocurrency Market.*  \n",
    "   *Expert Systems with Applications.*  \n",
    "   [Link](https://www.sciencedirect.com/science/article/abs/pii/S0957417422006339)\n",
    "\n",
    "9. **Yu, T.** (14 Dec 2023) *Dynamic Programming Based Optimal Trading Strategy Model of Volatile Assets.*  \n",
    "   *Association for Computing Machinery.*  \n",
    "   [Link](https://dl.acm.org/doi/10.1145/3624288.3624298)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
