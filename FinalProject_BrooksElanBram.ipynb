{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 188 - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Stock Market Trading Strategies: A Comparative Analysis\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Brooks Ephraim\n",
    "- Elan Hashem\n",
    "- Bram Simonnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "Our project explores AI-driven algorithmic trading strategies to optimize portfolio performance by predicting market trends and making informed trading decisions. We use historical stock data, including price movements, trading volume, and technical indicators, to develop predictive models. Our approach incorporates Neural Networks (NN), Temporal Difference (TD) Learning, and Dynamic Programming (DP) to forecast price changes and execute optimal trades. We evaluate model performance using financial metrics such as the Sharpe Ratio, total return, and average prediction error, comparing AI-driven strategies against the traditional Buy and Hold (BH) approach. Our results show that while BH outperforms most rule-based strategies in stable conditions, optimized AI models can generate higher portfolio returns when hyperparameters like train/test split and trade thresholds are tuned effectively. This study highlights the potential of AI in financial markets while acknowledging the important challenges of market volatility and overfitting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background (STILL NEED TO CHANGE)\n",
    "\n",
    "Fill in the background and discuss the kind of prior work that has gone on in this research area here. **Use inline citation** to specify which references support which statements.  You can do that through HTML footnotes (demonstrated here). I used to reccommend Markdown footnotes (google is your friend) because they are simpler but recently I have had some problems with them working for me whereas HTML ones always work so far. So use the method that works for you, but do use inline citations.\n",
    "\n",
    "Here is an example of inline citation. After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote). Use a minimum of 3 to 5 citations, but we prefer more <a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote). You need enough citations to fully explain and back up important facts. \n",
    "\n",
    "Remeber you are trying to explain why someone would want to answer your question or why your hypothesis is in the form that you've stated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Financial markets are inherently volatile, making it challenging to develop trading strategies that consistently outperform traditional approaches while managing risk. Initially, our goal was to maximize trading opportunities, but our focus developed towards predicting market trends and making informed trading decisions based on those predictions. This project integrates machine learning techniques, including Temporal Difference (TD) learning, Dynamic Programming (DP), and Neural Networks (NN), to optimize portfolio performance. By leveraging historical market data, we train models to predict price movements and identify optimal buy/sell points through backtracking and reinforcement learning principles. The effectiveness of our strategies is measured using key financial metrics such as the Sharpe ratio, total return, and prediction error. We benchmark our models against the Buy and Hold strategy to evaluate performance across different time periods and market conditions. Through hyperparameter tuning and company-wide analysis, we refine our models to maximize profitability while mitigating risk, ensuring adaptability in dynamic financial environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "### **Source and Structure**\n",
    "Our dataset was obtained from Yahoo Finance via the [Massive Yahoo Finance Dataset](https://www.kaggle.com/datasets/iveeaten3223times/massive-yahoo-finance-dataset) on Kaggle. It includes historical stock data for multiple companies, spanning several years, with daily and minute-level price observations.\n",
    "\n",
    "Each row in the dataset represents a timestamped stock price entry, typically structured as follows:\n",
    "- **Company**: Stock ticker symbol (e.g., AAPL, TSLA).\n",
    "- **Date**: Timestamp for the recorded data.\n",
    "- **Open, High, Low, Close Prices (OHLC)**: Standard stock price metrics.\n",
    "- **Adjusted Close**: Adjusted for stock splits and dividends.\n",
    "- **Volume**: The number of shares traded.\n",
    "\n",
    "After cleaning and preprocessing, our final dataset contained over **600,000 observations**, with essential financial metrics used for strategy evaluation.\n",
    "\n",
    "### **Data Cleaning and Preprocessing**\n",
    "To ensure high-quality inputs for our models, we applied the following preprocessing steps:\n",
    "\n",
    "#### **1. Handling Missing Data**\n",
    "- Dropped rows with missing OHLC prices to maintain data integrity.\n",
    "- Forward-filled missing values due to market closures on weekends and holidays.\n",
    "\n",
    "#### **2. Feature Engineering**\n",
    "To enhance model performance, we generated additional features:\n",
    "- Returns Calculation: Daily percentage change in stock price:\n",
    "  ```python\n",
    "  \n",
    "  df[\"Return\"] = df.groupby(\"Company\")[\"Close\"].pct_change()\n",
    "  ```\n",
    "- **Price Indicators**:\n",
    "  - Prev_Close: Closing price of the previous day.\n",
    "  - Price Change**: Difference between current and previous close price.\n",
    "  - Volatility: 5-day rolling standard deviation of closing prices.\n",
    "- **Technical Indicators**:\n",
    "  - **Simple Moving Averages (SMA)**:\n",
    "    ```python\n",
    "    df[\"SMA_10\"] = df.groupby(\"Company\")[\"Close\"].transform(lambda x: x.rolling(window=10, min_periods=1).mean())\n",
    "    df[\"SMA_50\"] = df.groupby(\"Company\")[\"Close\"].transform(lambda x: x.rolling(window=50, min_periods=1).mean())\n",
    "    ```\n",
    "\n",
    "#### **3. Data Transformation**\n",
    "- Converted timestamps to `datetime` format for easier time-series processing.\n",
    "- Sorted data by `Company` and `Date` to maintain chronological integrity.\n",
    "- Normalized price data where necessary for reinforcement learning models.\n",
    "\n",
    "\n",
    "## **Final Processed Dataset**\n",
    "- Companies Tracked: Multiple (e.g., AAPL, TSLA).\n",
    "- Observations: Over 600,000 records post-cleaning.\n",
    "- **Key Features Used**:\n",
    "  - OHLC prices\n",
    "  - Volume\n",
    "  - Returns\n",
    "  - Moving Averages\n",
    "  - Volatility\n",
    "\n",
    "This cleaned dataset was then used to train and evaluate different trading strategies, including reinforcement learning models (TD Learning, Dynamic Programming) and benchmarking against Buy-and-Hold strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    " \n",
    "Our approach optimizes algorithmic trading strategies by integrating reinforcement learning (TD Learning) and Dynamic Programming (DP) to make data-driven trading decisions. Instead of relying solely on rule-based or traditional statistical models, we use machine learning techniques to predict market movements and execute optimal buy/sell strategies.  \n",
    "\n",
    "##### **Problem Formulation: Trading as a Sequential Decision Process**\n",
    "We model the trading problem using Temporal Difference Learning and Dynamic Programming to determine the best buy, sell, or hold decisions based on historical stock data. Our goal is to maximize portfolio returns by learning from past market movements and optimizing trade execution.\n",
    "\n",
    "##### **1. State (S): Market Representation**\n",
    "Each state represents the market at a given time and includes:  \n",
    "- **OHLCV Data**: Open, High, Low, Close, Volume.  \n",
    "- **Technical Indicators**: Moving Averages (SMA, EMA), Volatility, Relative Strength Index (RSI), MACD.  \n",
    "- **Market Trends**: Rolling price changes, trend momentum.  \n",
    "- **Portfolio Status**: Current holdings, cash balance, previous transactions.\n",
    "\n",
    "##### **2. Actions (A): Trading Decisions**\n",
    "At each time step, the algorithm decides between:  \n",
    "- **Buy**: Purchase stock at the current price.  \n",
    "- **Sell**: Sell stock at the current price.  \n",
    "- **Hold**: Maintain the current position.\n",
    "\n",
    "##### **3. Reward Function (R): Incentivizing Profitability**\n",
    "- **Profit Maximization**: The reward function is defined as:\n",
    "\n",
    "\\[\n",
    "R_t = P_{t+1} - P_t\n",
    "\\]\n",
    "\n",
    "- **Transaction Costs**: Penalize excessive trading to minimize fees.  \n",
    "- **Holding Time Penalty**: Discourage holding onto a losing position for too long.\n",
    "\n",
    "##### **4. Dynamic Programming (DP) for Trade Optimization**\n",
    "Once TD Learning generates price predictions, Dynamic Programming (DP) is used to backtrack from the final date to identify optimal buy/sell points. By systematically evaluating potential trading decisions over time, DP finds the most profitable trades across the entire prediction window, outperforming naïve strategies.\n",
    "\n",
    "#### **Implementation Steps**\n",
    "1. **Data Preprocessing**: Clean and engineer features from Yahoo Finance data.  \n",
    "2. **TD Learning Prediction**: Train a reinforcement learning model on historical prices.  \n",
    "3. **DP Optimization**: Apply Dynamic Programming to maximize profit using predicted prices.  \n",
    "4. **Strategy Backtesting**: Compare TD+DP Trading Strategy against the Buy-and-Hold Benchmark using real stock market data.  \n",
    "5. **Performance Evaluation**: Measure effectiveness using Sharpe Ratio, Total Return, and Drawdowns.\n",
    "\n",
    "By combining machine learning, TD Learning, and Dynamic Programming, our approach enhances decision-making in trading and adapts dynamically to changing market conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "To assess the effectiveness of our AI-driven trading strategies, we employ multiple evaluation metrics that measure profitability, risk management, and model performance. These metrics allow us to compare our Temporal Difference Learning and Dynamic Programming methods against traditional strategies like Buy & Hold and other benchmark models. Below, we outline the key evaluation criteria used in our analysis.\n",
    "\n",
    "### **Profitability & Risk-Adjusted Returns**\n",
    "**1. Sharpe Ratio**\n",
    "\n",
    "The Sharpe Ratio is a fundamental measure in finance that evaluates the risk-adjusted return of an investment strategy. A higher Sharpe ratio indicates better returns per unit of risk, making it a critical metric for comparing our AI models to benchmarks.\n",
    "\n",
    "Mathematically, the Sharpe Ratio is defined as:\n",
    "\n",
    "Sharpe Ratio = (Rx – Rf) / StdDev Rx \n",
    "- Rx = Expected portfolio return \n",
    "- Rf = Risk-free rate of return. \n",
    "- StdDev Rx = Standard deviation of portfolio return (or, volatility)\n",
    "\n",
    "```python\n",
    "def calculate_sharpe_ratio(returns, risk_free_rate=0.01):\n",
    "    excess_returns = np.array(returns) - risk_free_rate  \n",
    "    std_dev = np.std(excess_returns, ddof=1)  \n",
    "\n",
    "    return np.inf if std_dev == 0 else np.mean(excess_returns) / std_dev\n",
    "```\n",
    "\n",
    "We use this ratio in BENCHMARK_EVAL.py to compare the Sharpe ratios of:\n",
    "- Buy & Hold Strategy\n",
    "- TD Learning Strategy\n",
    "- DP Strategy\n",
    "- Other benchmark strategies (e.g., SMA, EMA, MACD)\n",
    "\n",
    "### Trading Strategies Evaluated\n",
    "We implemented and backtested 8 different trading strategies:\n",
    "\n",
    "| **Strategy** | **Description** |\n",
    "|-------------|----------------|\n",
    "| **Simple Moving Average (SMA)** | Uses short- and long-term moving averages for buy/sell signals. |\n",
    "| **Exponential Moving Average (EMA)** | Similar to SMA but gives more weight to recent prices. |\n",
    "| **Mean Reversion** | Buys undervalued stocks and sells overvalued ones based on deviation from SMA. |\n",
    "| **Momentum Trading** | Rides trends by buying when prices increase and selling when they decrease. |\n",
    "| **Moving Average Crossover (MAC)** | Combines SMA and momentum for trade signals. |\n",
    "| **Scalping Strategy** | Executes quick trades on small price movements. |\n",
    "| **Swing Trading** | Identifies medium-term price swings for entries/exits. |\n",
    "| **Buy-and-Hold (Benchmark)** | Holds stocks long-term, serving as the **baseline** strategy. |\n",
    "\n",
    "Each strategy applies a **buy/sell signal** based on different technical indicators, such as moving averages, price deviations, and momentum calculations.\n",
    "\n",
    "Example of Simple Moving Average (SMA):\n",
    "\n",
    "```python\n",
    "df[\"SMA_Short\"] = df.groupby(\"Company\")[\"Close\"].transform(lambda x: x.rolling(window=5, min_periods=1).mean())\n",
    "df[\"SMA_Long\"] = df.groupby(\"Company\")[\"Close\"].transform(lambda x: x.rolling(window=100, min_periods=1).mean())\n",
    "\n",
    "df[\"SMA_Signal\"] = 0\n",
    "df.loc[df[\"SMA_Short\"] > df[\"SMA_Long\"], \"SMA_Signal\"] = 1  # Buy\n",
    "df.loc[df[\"SMA_Short\"] < df[\"SMA_Long\"], \"SMA_Signal\"] = -1  # Sell\n",
    "```\n",
    "Each strategy was **backtested** by multiplying returns by its respective trading signals.\n",
    "\n",
    "\n",
    "\n",
    "### Results: Sharpe Ratio Comparison\n",
    "We computed Sharpe Ratios for each strategy to determine the most profitable and risk-efficient approach.\n",
    "\n",
    "```python\n",
    "print(\"Sharpe Ratios for Trading Strategies\")\n",
    "print(f\" SMA Strategy Sharpe Ratio: {sma_sharpe:.4f}\")\n",
    "print(f\" EMA Strategy Sharpe Ratio: {ema_sharpe:.4f}\")\n",
    "print(f\" Mean Reversion Strategy Sharpe Ratio: {mean_reversion_sharpe:.4f}\")\n",
    "print(f\" Momentum Strategy Sharpe Ratio: {momentum_sharpe:.4f}\")\n",
    "print(f\" MAC Strategy Sharpe Ratio: {mac_sharpe:.4f}\")\n",
    "print(f\" Scalping Strategy Sharpe Ratio: {scalping_sharpe:.4f}\")\n",
    "print(f\" Swing Trading Strategy Sharpe Ratio: {swing_sharpe:.4f}\")\n",
    "print(f\" Buy-and-Hold Strategy Sharpe Ratio: {buy_hold_sharpe:.4f}\")\n",
    "```\n",
    "\n",
    "### **Model Performance & Prediction Accuracy**\n",
    "**2. Average Prediction Error**\n",
    "\n",
    "To evaluate our market prediction model, we measure the average prediction error, comparing:\n",
    "- Predicted closing prices from TD Learning & DP\n",
    "- Actual closing prices in the market.\n",
    "\n",
    "This allows us to quantify how well our model forecasts market movements, impacting trade execution quality.\n",
    "\n",
    "\\[\n",
    "Average Prediction Error = 1/N sum(t=1)^N | P{predicted} - P{actual} |\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- P{predicted} = Predicted stock price at time t\n",
    "- P{actual} = Actual stock price at time t\n",
    "- N = Total number of observations\n",
    "\n",
    "This measures the average absolute difference between the predicted and actual prices.\n",
    "\n",
    "\n",
    "\n",
    "#### Interpreting APE Results\n",
    "- Lower APE → Better predictions: Our model is accurately forecasting stock prices.\n",
    "- Higher APE → Worse predictions: The model struggles to capture market trends.\n",
    "- Comparison between models: If TD Learning has lower APE than DP, TD is better at forecasting.\n",
    "\n",
    "#### Why is APE Important?\n",
    "- Benchmarks the accuracy of AI-driven predictions.\n",
    "- Guides model improvements (e.g., tuning hyperparameters).\n",
    "- Validates whether AI models outperform traditional methods.\n",
    "\n",
    "#### Python Implementation \n",
    "\n",
    "We implement this metric in **PARENT_AAPL.py**, where we apply TD Learning and DP models to predict stock prices.\n",
    "\n",
    "```python\n",
    "\n",
    "# --- Compute Average Prediction Error (APE) ---\n",
    "def calculate_ape(actual_prices, predicted_prices):\n",
    "    \"\"\"\n",
    "    Compute Average Prediction Error (APE)\n",
    "    \"\"\"\n",
    "    errors = np.abs(actual_prices - predicted_prices)\n",
    "    return np.mean(errors)\n",
    "\n",
    "# Remove NaN values\n",
    "valid_data = test_df.dropna(subset=[\"Predicted_Close\"])\n",
    "actual_prices = valid_data[\"Close\"].values\n",
    "predicted_prices = valid_data[\"Predicted_Close\"].values\n",
    "\n",
    "# Compute APE\n",
    "average_prediction_error = calculate_ape(actual_prices, predicted_prices)\n",
    "\n",
    "print(f\" Average Prediction Error (APE): {average_prediction_error:.4f}\")\n",
    "```\n",
    "\n",
    "\n",
    "### **Portfolio Performance Comparison**\n",
    "**3. Portfolio Profitability**\n",
    "\n",
    "To assess portfolio profitability, we compare TD & DP trading models against the Buy & Hold strategy over the same time period, using metrics such as:\n",
    "\n",
    "**Total Return (%)**\n",
    "\n",
    "\\[\n",
    "Total Return = [Final Portfolio Value - Initial Investment / Initial Investment] x 100\n",
    "\\]\n",
    "- Higher total return = More profitable strategy  \n",
    "<br>\n",
    "\n",
    "**4. Weighted Average Performance: Evaluating Multiple Companies**  \n",
    "\n",
    "In our study, we expand from analyzing a single stock (e.g., AAPL) to evaluating multiple companies to ensure our model's generalizability. To achieve this, we compute a weighted average performance metric across different stocks, ensuring that larger companies (with more significant market impact) are properly accounted for in our evaluation.\n",
    "\n",
    "Why Use Weighted Averages?\n",
    "A simple arithmetic mean would treat all stocks equally, which is unrealistic. Stocks with larger market capitalization or higher trading volume have a greater influence on the market and should carry more weight in our evaluation. \n",
    "\n",
    "To ensure fair comparison, we use a weighted average, where:\n",
    "1. Portfolio returns are weighted based on the company’s trading volume or market capitalization.\n",
    "2. Larger companies contribute more to the final metric, aligning with real-world financial analysis.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Mathematical Representation**\n",
    "<br>\n",
    "\n",
    "We compute the weighted portfolio return using the formula:\n",
    "\n",
    "\\[\n",
    "Weighted Average Return = [ (sum_{i=1}^{N} w_i R_i) / sum_{i=1}^{N}w_i ]\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( R_i \\) = Return for company \\( i \\)  \n",
    "- \\( w_i \\) = Weight assigned to company \\( i \\) (based on trading volume or market cap)  \n",
    "- \\( N \\) = Total number of companies  \n",
    "\n",
    "This ensures that a high-volume stock like AAPL influences the average more than a low-volume stock.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Implementation in Code**\n",
    "\n",
    "We implement this approach in **AVG_COMPANY.py**, where we compute weighted performance across multiple stocks.\n",
    "\n",
    "```python\n",
    "# Compute daily returns\n",
    "df[\"Return\"] = df.groupby(\"Company\")[\"Close\"].pct_change()\n",
    "df = df.dropna(subset=[\"Return\"])  # Drop missing returns\n",
    "\n",
    "# Define weights based on trading volume (alternative: use market cap)\n",
    "df[\"Weight\"] = df.groupby(\"Company\")[\"Volume\"].transform(lambda x: x / x.sum())\n",
    "\n",
    "# Compute weighted returns for each strategy\n",
    "df[\"Weighted_Return\"] = df[\"Weight\"] * df[\"Return\"]\n",
    "\n",
    "# Compute weighted Sharpe Ratio\n",
    "def calculate_weighted_sharpe(df, risk_free_rate=0.01):\n",
    "    weighted_avg_return = df[\"Weighted_Return\"].mean()\n",
    "    std_dev = df[\"Weighted_Return\"].std()\n",
    "\n",
    "    return np.inf if std_dev == 0 else (weighted_avg_return - risk_free_rate) / std_dev\n",
    "\n",
    "# Compute weighted portfolio Sharpe ratio\n",
    "weighted_sharpe = calculate_weighted_sharpe(df)\n",
    "\n",
    "print(f\"Weighted Portfolio Sharpe Ratio: {weighted_sharpe:.4f}\")\n",
    "```\n",
    "<br>\n",
    "Key Adjustments for Our Analysis\n",
    "\n",
    "In **AVG_COMPANY.py**, we:\n",
    "1. Weight returns based on trading volume to ensure large stocks influence results more.\n",
    "2. Compute a weighted Sharpe Ratio, rather than treating each company equally.\n",
    "3. Evaluate performance across an entire portfolio instead of just one stock.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Why Is This Important?\n",
    "- Accounts for Real-World Market Influence: Large-cap stocks (like AAPL, TSLA) affect market trends more than small stocks.\n",
    "- Ensures Stability in Results: A single company’s outlier performance doesn’t dominate the overall analysis.\n",
    "- Improves Generalizability: Models trained on a diverse, weighted dataset are more robust.\n",
    "\n",
    "This method ensures our AI trading model is tested fairly across multiple companies rather than overfitting to a single stock.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "### 1. Analysis of the Dataset\n",
    "\n",
    "**How Data Influenced Model Selection:**\n",
    "- Initial exploration showed that stock prices followed trends, suggesting that momentum-based strategies (SMA, EMA) might be effective.\n",
    "- However, Buy and Hold consistently outperformed simple rule-based strategies across different timeframes.\n",
    "- This motivated us to explore reinforcement learning approaches:\n",
    "  - Temporal Difference (TD) Learning to iteratively update value functions and predict various future values depending on train-test splits.\n",
    "  - Dynamic Programming (DP) Strategy to optimize buy/sell decisions based on learned predictions.\n",
    "- The dataset’s varying volatility across companies indicated that hyperparameter tuning would be critical to optimize strategy performance.\n",
    "\n",
    "These insights guided our benchmark model selection and reinforcement learning approach, which we discuss next.\n",
    "\n",
    "\n",
    "### 2. Benchmark Model Selection\n",
    "\n",
    "**Choosing the Timeframe:**\n",
    "\n",
    "To determine the best benchmark strategy, we analyzed performance across three different time periods:\n",
    "1. Before COVID-19\n",
    "2. After COVID-19\n",
    "3. The entire timeline\n",
    "\n",
    "Using **`TIMELINE.py`**, we computed the Sharpe Ratio for each strategy in all three periods. We found that:\n",
    "- Buy and Hold outperformed all other strategies in every timeframe.\n",
    "- This means timeframe selection had minimal impact on the best-performing benchmark.\n",
    "- Thus, we used Buy and Hold as our benchmark for further comparisons.\n",
    "\n",
    "\n",
    "**Sharpe Ratios for Trading Strategies**\n",
    "- SMA Strategy Sharpe Ratio: -0.4684\n",
    "- EMA Strategy Sharpe Ratio: -0.4612\n",
    "- Mean Reversion Strategy Sharpe Ratio: -0.5731\n",
    "- Momentum Strategy Sharpe Ratio: -0.4566\n",
    "- MAC Strategy Sharpe Ratio: -0.6221\n",
    "- Buy-and-Hold Strategy Sharpe Ratio: 0.3573\n",
    "\n",
    "\n",
    "All trading strategies had negative Sharpe Ratios, indicating poor risk-adjusted performance.\n",
    "- Buy and Hold had the highest Sharpe Ratio (0.3573), making it the clear benchmark strategy.\n",
    "\n",
    "#### **Evaluation**\n",
    "\n",
    "We implemented several trading strategies using Simple Moving Averages (SMA), Exponential Moving Averages (EMA), Momentum, and Mean Reversion, but none of them outperformed Buy and Hold.\n",
    "\n",
    "**SMA**\n",
    "\n",
    "The Simple Moving Average (SMA) is a widely used technical indicator in stock trading. It calculates the average of a stock's closing prices over a fixed number of past days, smoothing out fluctuations to reveal trends.\n",
    "\n",
    "SMA is used to identify bullish or bearish trends:\n",
    "\n",
    "- If a short-term SMA (e.g., 5-day) crosses above a long-term SMA (e.g., 100-day), it generates a buy signal (bullish crossover).\n",
    "- If the short-term SMA drops below the long-term SMA, it generates a sell signal (bearish crossover).\n",
    "\n",
    "**Why We Thought SMA Would Work Well**\n",
    "\n",
    "- Clear Trend Identification: By smoothing out noise, SMA should help identify when to buy and sell.\n",
    "- Widely Used: Many traders use SMA crossovers, so we expected it to have strong predictive power.\n",
    "- Historical Support: In certain markets, SMA strategies have shown profitability in past studies.\n",
    "\n",
    "However, despite our expectations, SMA underperformed significantly compared to Buy-and-Hold.\n",
    "\n",
    "After implementing the SMA strategy and computing its Sharpe Ratio, we observed a negative Sharpe Ratio (-0.4684), indicating poor risk-adjusted returns.\n",
    "\n",
    "**Reasons for SMA's Poor Performance**\n",
    "\n",
    "**1. Delayed Reactions:**\n",
    "- SMA is a lagging indicator, meaning it reacts slowly to price changes.\n",
    "- This resulted in late buy/sell decisions, causing us to miss good entry/exit points.\n",
    "\n",
    "**2. Frequent False Signals:**\n",
    "- The market does not always follow clean trends, leading to whipsaws (false signals causing unnecessary trades).\n",
    "- Increased trading meant higher transaction costs, further hurting performance.\n",
    "\n",
    "**3. Market Trends Are Often Sustained:**\n",
    "- The stock market generally follows long-term upward trends.\n",
    "- SMA often forced unnecessary exits when the price briefly dipped, whereas Buy-and-Hold stayed invested and benefited from long-term gains.\n",
    "\n",
    "After SMA failed, we tested Exponential Moving Average (EMA) and Moving Average Crossover with Momentum (MAC).\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Exponential Moving Average (EMA)**\n",
    "\n",
    "EMA is similar to SMA but gives more weight to recent prices, making it more responsive to trends.\n",
    "\n",
    "**Why EMA Should Have Worked**\n",
    "\n",
    "- Faster Response to Trends: EMA adapts more quickly than SMA, potentially reducing lag.\n",
    "- More Dynamic Buy/Sell Signals: Could react quicker to price reversals.\n",
    "\n",
    "**Why EMA Failed**\n",
    "\n",
    "Despite being more responsive, EMA still lagged behind sharp market movements.\n",
    "- Sharpe Ratio: -0.4612 → slightly better than SMA but still negative.\n",
    "\n",
    "Still subject to false signals in volatile markets.\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "**Moving Average Crossover with Momentum (MAC)**\n",
    "\n",
    "MAC combines SMA crossovers with momentum analysis to confirm trends.\n",
    "​\n",
    " \n",
    "Momentum_t = P_t - P_t - n​\n",
    " \n",
    "where:\n",
    "\n",
    "- If momentum is positive, price is increasing.\n",
    "- If momentum is negative, price is decreasing.\n",
    "\n",
    "How It Works:\n",
    "\n",
    "1. If a short-term SMA crosses above a long-term SMA, check if momentum is positive.\n",
    "2. If yes → BUY. If no → ignore the signal.\n",
    "3. If a short-term SMA drops below a long-term SMA, check if momentum is negative.\n",
    "4. If yes → SELL.\n",
    "\n",
    "\n",
    "**Why MAC Should Have Worked**\n",
    "\n",
    "- It filters out false signals by confirming trends with momentum.\n",
    "- Could provide stronger buy/sell signals than SMA alone.\n",
    "\n",
    "\n",
    "**Why MAC Failed**\n",
    "- Sharpe Ratio: -0.6221 → even worse than SMA and EMA.\n",
    "- Too conservative, missing good trades by waiting for extra confirmation.\n",
    "\n",
    "Still not responsive enough to quick trend reversals.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Why did Buy-and-Hold Outperform?**\n",
    "- Lower trading costs (fewer transactions).  \n",
    "- Long-term growth captured without frequent exits.  \n",
    "- Less exposed to false signals from market fluctuations.  \n",
    "\n",
    "### 3. Case Study: Apple – Comparing Temporal Difference Learning and Dynamic Programming Against Buy-and-Hold\n",
    "In this subsection, we analyze Apple Inc. (AAPL) to demonstrate our process of applying Temporal Difference Learning and Dynamic Programming as trading strategies, comparing their performance to the Buy-and-Hold strategy. The insights gained from this example will later help us generalize our findings to other stocks, such as Tesla (TSLA).\n",
    "\n",
    "**Why We Chose AAPL for This Analysis**\n",
    "\n",
    "AAPL was selected as our primary example for several reasons:\n",
    "\n",
    "- High trading volume and liquidity → Ensures a smoother price trend with fewer market anomalies.\n",
    "- Consistent long-term growth → Helps evaluate how predictive strategies perform against a well-established uptrend.\n",
    "- Rich historical data → Allows for more reliable backtesting of our models.\n",
    "\n",
    "To analyze AAPL, we applied TD Learning and DP on the stock price data and compared the resulting portfolio performance against Buy-and-Hold.\n",
    "\n",
    "**Implementing TD Learning for Price Prediction**\n",
    "\n",
    "Temporal Difference Learning is a reinforcement learning technique that updates value predictions incrementally based on observed rewards. Our TD agent learns to predict AAPL's closing prices and refines its predictions over time.\n",
    "\n",
    "**Key Components of the TD Model**\n",
    "- `alpha` (learning rate): Determines how much the model updates its predictions based on new information.\n",
    "- `gamma` (discount factor): Balances immediate vs. future rewards.\n",
    "- State Representation: The previous closing price serves as the input state for the TD model.\n",
    "- Reward Function: The price difference between consecutive days serves as the reward.\n",
    "\n",
    "##### **TD Learning Code**\n",
    "```python\n",
    "class TDLearning:\n",
    "    def __init__(self, alpha=0.1, gamma=0.9):\n",
    "        self.alpha = alpha  \n",
    "        self.gamma = gamma  \n",
    "        self.value_function = {}  \n",
    "\n",
    "    def predict(self, state):\n",
    "        stored_value = self.value_function.get(state, 0)\n",
    "        if stored_value < state * 0.5:\n",
    "            return state  \n",
    "        return stored_value\n",
    "\n",
    "    def update(self, state, reward, next_state):\n",
    "        current_value = self.predict(state)\n",
    "        next_value = self.predict(next_state)\n",
    "        self.value_function[state] = current_value + self.alpha * (reward + self.gamma * next_value - current_value)\n",
    "\n",
    "    def train(self, data):\n",
    "        for i in range(len(data)):\n",
    "            price = data.iloc[i][\"Close\"]\n",
    "            if price not in self.value_function:\n",
    "                self.value_function[price] = price\n",
    "        \n",
    "        for i in range(1, len(data)):\n",
    "            current_price = data.iloc[i - 1][\"Close\"]\n",
    "            next_price = data.iloc[i][\"Close\"]\n",
    "            reward = next_price - current_price  \n",
    "            self.update(current_price, reward, next_price)\n",
    "```\n",
    "\n",
    "**Code Breakdown**\n",
    "\n",
    "| **Method**        | **Purpose** | **Key Operations** | **Why It’s Important?** |\n",
    "|-------------------|------------|--------------------|--------------------------|\n",
    "| `__init__(self, alpha=0.1, gamma=0.9)` | Initializes learning rate (`alpha`), discount factor (`gamma`), and stores past price values. | - Sets `alpha = 0.1` (controls how much predictions change).  <br> - Sets `gamma = 0.9` (importance of future prices).  <br> - Initializes `value_function` (stores predicted values for stock prices). | Prepares the model by defining how much it learns from price changes. |\n",
    "| `predict(self, state)` | Returns the stored value of a stock price or initializes it if unseen. | - Checks if `state` (stock price) exists in `value_function`.  <br> - If the value is too low (less than 50% of `state`), it assumes `state` as the value.  <br> - Otherwise, it returns the stored value. | Ensures reasonable initial estimates, avoiding drastic underestimation of stock prices. |\n",
    "| `update(self, state, reward, next_state)` | Applies the TD learning formula to refine stock price predictions. | - Retrieves current value of `state` and `next_state`.  <br> - Computes TD update rule:  <br> `New Value = Old Value + α * (Reward + γ * Next Value - Old Value)` | Gradually improves predictions by incorporating real price changes into future estimates. |\n",
    "| `train(self, data)` | Iterates through historical stock prices, updating predictions based on daily price changes. | - Initializes `value_function` for all closing prices.  <br> - Loops through historical stock data.  <br> - Computes reward as the daily price change.  <br> - Calls `update()` to refine predictions. | Mimics real trading behavior by learning from historical data and improving over time. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.\n",
    "\n",
    "\n",
    "### Limitations\n",
    "\n",
    "Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?   \n",
    "\n",
    "\n",
    "### Future work\n",
    "Looking at the limitations and/or the toughest parts of the problem and/or the situations where the algorithm(s) did the worst... is there something you'd like to try to make these better.\n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "If your project has obvious potential concerns with ethics or data privacy discuss that here.  Almost every ML project put into production can have ethical implications if you use your imagination. Use your imagination.\n",
    "\n",
    "Even if you can't come up with an obvious ethical concern that should be addressed, you should know that a large number of ML projects that go into producation have unintended consequences and ethical problems once in production. How will your team address these issues?\n",
    "\n",
    "Consider a tool to help you address the potential issues such as https://deon.drivendata.org\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.<br>\n",
    "<a name=\"sotanote\"></a>3.[^](#sota): Perhaps the current state of the art solution such as you see on [Papers with code](https://paperswithcode.com/sota). Or maybe not SOTA, but rather a standard textbook/Kaggle solution to this kind of problem\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "A4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
